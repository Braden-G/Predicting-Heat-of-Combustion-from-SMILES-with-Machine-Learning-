{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in c:\\users\\brade\\anaconda3\\envs\\final_project\\lib\\site-packages (2024.3.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\brade\\anaconda3\\envs\\final_project\\lib\\site-packages (from rdkit) (1.26.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\brade\\anaconda3\\envs\\final_project\\lib\\site-packages (from rdkit) (11.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDFingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fingerprints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 36\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing SMILES \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msmiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m feature_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(\u001b[43mfingerprints\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fingerprints' is not defined"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import numpy as np\n",
    "\n",
    "def smiles_to_ecfp4(smiles, n_bits=2048):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to an ECFP4 fingerprint.\n",
    "    \n",
    "    Args:\n",
    "        smiles (str): The SMILES string of a molecule.\n",
    "        n_bits (int): Length of the fingerprint vector (default is 2048).\n",
    "    \n",
    "    Returns:\n",
    "        np.array: A binary fingerprint array.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert SMILES to RDKit molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            raise ValueError(\"Invalid SMILES\")\n",
    "        \n",
    "        # Generate ECFP4 fingerprint\n",
    "        mfpgen = rdFingerprintGenerator.GetMorganGenerator(fpSize=n_bits)\n",
    "        morgan_fp = mfpgen.GetFingerprint(mol)\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        arr = np.zeros((n_bits,), dtype=int)\n",
    "        Chem.DataStructs.ConvertToNumpyArray(morgan_fp, arr)\n",
    "        return arr\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing SMILES {smiles}: {e}\")\n",
    "        return None\n",
    "    \n",
    "     \n",
    "# feature_matrix = np.vstack(fingerprints)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chemBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the chemBERTa model and tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"seyonec/PubChem10M_SMILES_BPE_450k\")\n",
    "model = TFRobertaModel.from_pretrained(\"seyonec/PubChem10M_SMILES_BPE_450k\", from_pt=True)\n",
    "\n",
    "def smiles_to_chemberta_embedding(smiles):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to a chemBERTa embedding.\n",
    "    \n",
    "    Args:\n",
    "        smiles (str): The SMILES string of a molecule.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: The chemBERTa embedding.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Tokenize the SMILES string\n",
    "        inputs = tokenizer(smiles, return_tensors=\"tf\")\n",
    "        \n",
    "        # Generate embeddings\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Get the embeddings from the last hidden state\n",
    "        embeddings = tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy()\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing SMILES {smiles}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chemBERTa prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.4256042  -1.3949604   1.5881201  ... -0.00274044  0.25688475\n",
      "  -0.29546866]\n",
      " [-1.4463953  -1.7581638   0.9259674  ... -0.88145083  0.28398564\n",
      "  -0.0378332 ]\n",
      " [-1.9992245  -1.5124565   1.2577149  ... -1.4636784   0.14179237\n",
      "   0.27983335]\n",
      " ...\n",
      " [-0.41555628 -0.8626808   1.0436213  ... -0.1684835   0.21819799\n",
      "  -0.26750368]\n",
      " [-0.637986   -0.19990233  1.4843488  ... -1.1413604   0.8553332\n",
      "  -0.59937996]\n",
      " [ 0.22246566 -0.5423054   0.8084985  ...  0.28055328  0.30308014\n",
      "   0.46292472]]\n",
      "Size of one embedding: (1, 768)\n",
      "[[-1.4639498  -2.090591    1.9159063  ...  0.4178756   0.24905889\n",
      "  -0.26775038]\n",
      " [-2.075873   -1.5415013   1.9413147  ...  0.35351324  0.32953373\n",
      "   0.0907841 ]\n",
      " [-2.6733763  -1.445852    1.6646048  ...  0.8060034   0.0337576\n",
      "   0.11659135]\n",
      " ...\n",
      " [-0.34806222 -0.06990272  0.31357646 ... -0.12339465 -0.10441314\n",
      "  -0.31312   ]\n",
      " [ 0.11035563 -0.12319657  0.22988446 ...  0.104612    0.3350938\n",
      "  -0.47396162]\n",
      " [-0.30993482 -0.6233391  -0.02259463 ... -1.0125186   0.70143855\n",
      "  -0.20651408]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('SyntheticData.csv')\n",
    "# data.head()\n",
    "input = data['Smile']\n",
    "output = data['Heat of Combustion']\n",
    "\n",
    "# Convert SMILES to chemBERTa embeddings\n",
    "chemberta_embeddings = [smiles_to_chemberta_embedding(s) for s in input]\n",
    "\n",
    "# Convert to numpy array\n",
    "feature_matrix = np.vstack(chemberta_embeddings)\n",
    "print(feature_matrix)\n",
    "\n",
    "test_data = pd.read_csv('testing_data.csv')\n",
    "# test_data.head()\n",
    "test_input = test_data['Smile']\n",
    "test_output = test_data['Heat of Combustion']\n",
    "\n",
    "# Convert test SMILES to chemBERTa embeddings\n",
    "test_chemberta_embeddings = [smiles_to_chemberta_embedding(s) for s in test_input]\n",
    "# Print the size of one of the embeddings\n",
    "print(f\"Size of one embedding: {test_chemberta_embeddings[0].shape}\")\n",
    "\n",
    "# Convert to numpy array\n",
    "test_feature_matrix = np.vstack(test_chemberta_embeddings)\n",
    "print(test_feature_matrix)\n",
    "\n",
    "# Write the feature_matrix to a file\n",
    "# np.save('embeddings/chemBertaEmbeddings.npy', feature_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prefered embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('clean_full_combustion_with_smile.csv')\n",
    "# data.head()\n",
    "input = data['Smile']\n",
    "output = data['Heat of Combustion']\n",
    "# Choose embedding type\n",
    "# feature_matrix = np.load('embeddings/ecfp4Embeddings.npy')\n",
    "feature_matrix = np.load('embeddings/chemBertaEmbeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "R-squared: 0.09610684852917839\n",
      "Mean Absolute Error: 1896.836579739843\n",
      "Mean Squared Error: 7353301.653098491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, output, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameters directly\n",
    "best_params = {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "\n",
    "# Create the RandomForestRegressor model with the best parameters\n",
    "best_model = RandomForestRegressor(**best_params)\n",
    "\n",
    "# Train the best model\n",
    "model = best_model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = model.score(X_test, y_test)\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "mae = np.mean(np.abs(predictions - y_test))\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost \n",
    "Consistently the lowest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 12084850.46010613\n",
      "Average R-squared: -0.04456005414072426\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the best parameters\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.8}\n",
    "\n",
    "# Create the XGBRegressor model with the best parameters\n",
    "best_model = XGBRegressor(**best_params)\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    best_model.fit(X_tr, y_tr)\n",
    "    val_predictions = best_model.predict(X_val)\n",
    "    \n",
    "    mse_scores.append(mean_squared_error(y_val, val_predictions))\n",
    "    r2_scores.append(best_model.score(X_val, y_val))\n",
    "\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "print(f\"Average R-squared: {np.mean(r2_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "Fast and highest accuracy so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 9525979.88032572\n",
      "Average MAE: 1754.5031615690343\n",
      "Average R-squared: 0.17999267181989503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Apply the best parameters found from grid search directly to the SVR model\n",
    "best_params = {'C': 10, 'degree': 2, 'epsilon': 0.5, 'gamma': 'scale', 'kernel': 'linear'}\n",
    "best_model = SVR(**best_params)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(feature_matrix):\n",
    "    X_tr, X_val = feature_matrix[train_index], feature_matrix[val_index]\n",
    "    y_tr, y_val = output.iloc[train_index], output.iloc[val_index]\n",
    "    \n",
    "    best_model.fit(X_tr, y_tr)\n",
    "    val_predictions = best_model.predict(X_val)\n",
    "    \n",
    "    mse_scores.append(mean_squared_error(y_val, val_predictions))\n",
    "    mae_scores.append(np.mean(np.abs(val_predictions - y_val)))\n",
    "    r2_scores.append(best_model.score(X_val, y_val))\n",
    "\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "print(f\"Average MAE: {np.mean(mae_scores)}\")\n",
    "print(f\"Average R-squared: {np.mean(r2_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Needs work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Average MSE: 2788282.065055718\n",
      "Average R-squared: 0.8672423322067074\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_202 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24576</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_203 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,572,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_204 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_205 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_206 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_207 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_208 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_209 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_202 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_27 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24576\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_203 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m1,572,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_81 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_204 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_205 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_82 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_206 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_83 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_207 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_208 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_209 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,781,573</span> (18.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,781,573\u001b[0m (18.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,593,857</span> (6.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,593,857\u001b[0m (6.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,187,716</span> (12.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,187,716\u001b[0m (12.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense, Input, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the CNN model\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    # test dense compared to convolutoinal\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(feature_matrix):\n",
    "    X_tr, X_val = feature_matrix[train_index], feature_matrix[val_index]\n",
    "    y_tr, y_val = output.iloc[train_index], output.iloc[val_index]\n",
    "    \n",
    "    # Reshape the input data to fit the CNN model\n",
    "    X_tr = X_tr.reshape((X_tr.shape[0], X_tr.shape[1], 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "    \n",
    "    # Create and train the CNN model\n",
    "    model = create_cnn_model((X_tr.shape[1], 1))\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_tr, y_tr, epochs=10000, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_predictions = model.predict(X_val)\n",
    "    mse_scores.append(mean_squared_error(y_val, val_predictions))\n",
    "    # mae_scores.append(np.mean(np.abs(val_predictions - y_val)))\n",
    "\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "# print(f\"Average MAE: {np.mean(mae_scores)}\")\n",
    "# Calculate R-squared value\n",
    "r2_scores = [model.evaluate(X_val, y_val, verbose=0) for train_index, val_index in kf.split(feature_matrix)]\n",
    "average_r2 = 1 - np.mean(r2_scores) / np.var(output)\n",
    "print(f\"Average R-squared: {average_r2}\")\n",
    "print(\"-----------------------------------\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Test MSE: 4984136.111082153\n",
      "Test MAE: 1633.4812698216933\n",
      "Test R-squared: 0.2304650778791445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Reshape the test feature matrix for the CNN model\n",
    "test_feature_matrix_reshaped = test_feature_matrix.reshape((test_feature_matrix.shape[0], test_feature_matrix.shape[1], 1))\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(test_feature_matrix_reshaped)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse_test = mean_squared_error(test_output, test_predictions)\n",
    "mae_test = mean_absolute_error(test_output, test_predictions)\n",
    "r2_test = r2_score(test_output, test_predictions)\n",
    "\n",
    "print(f\"Test MSE: {mse_test}\")\n",
    "print(f\"Test MAE: {mae_test}\")\n",
    "print(f\"Test R-squared: {r2_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data vs Synthetic Data Results\n",
    "\n",
    "| Metric                | Neural Net (Training Data) | Neural Net (Synthetic Data) | CNN (Training Data) | CNN (Synthetic Data) |\n",
    "|-----------------------|----------------------------|-----------------------------|----------------------|-----------------------|\n",
    "| **Average MSE**       | 9,794,885        | 2,788,282         | 9,780,797  | 2,500,507   |\n",
    "| **Average R-squared** | 0.7848886029948038        | 0.8672423322067074          | 0.7871524146612794   | 0.7930993420803031    |\n",
    "| **Test MSE**          | 4,700,471       | 4,984,136         | 4,624,448  | 4,913,290   |\n",
    "| **Test MAE**          | 1,767       | 1,633         | 1,713   | 1,558   |\n",
    "| **Test R-squared**    | 0.2742619564594171        | 0.2304650778791445          | 0.28599978637983003  | 0.2414033579524828    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_example(sample_index):\n",
    "    print(\"Sample Index:\", sample_index, \"of\", len(test_input))\n",
    "\n",
    "    # Get the example input, prediction, and target\n",
    "    example_input = test_input.iloc[sample_index]\n",
    "    example_prediction = test_predictions[sample_index][0]\n",
    "    example_target = test_output.iloc[sample_index]\n",
    "    # Calculate the difference\n",
    "    difference = abs(example_prediction - example_target)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Testing Input (SMILES): {example_input}\")\n",
    "    print(f\"Model Prediction: {example_prediction:.2f}\")\n",
    "    print(f\"Actual Value: {example_target:.2f}\")\n",
    "    print(f\"Difference: {difference:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select an example index from the test set\u001b[39;00m\n\u001b[0;32m      2\u001b[0m example_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m  \u001b[38;5;66;03m# You can change this index to test other samples\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mget_test_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mget_test_example\u001b[1;34m(sample_index)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_test_example\u001b[39m(sample_index):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample Index:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_input\u001b[49m))\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Get the example input, prediction, and target\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     example_input \u001b[38;5;241m=\u001b[39m test_input\u001b[38;5;241m.\u001b[39miloc[sample_index]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_input' is not defined"
     ]
    }
   ],
   "source": [
    "# Select an example index from the test set\n",
    "example_index = 15  # You can change this index to test other samples\n",
    "get_test_example(example_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 180ms/step - loss: 18189822.0000 - val_loss: 9017719.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 18406246.0000 - val_loss: 8968423.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 12757139.0000 - val_loss: 8900638.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 12173156.0000 - val_loss: 8809048.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 13690339.0000 - val_loss: 8690604.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 14152281.0000 - val_loss: 8543607.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 17652630.0000 - val_loss: 8363805.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 18108696.0000 - val_loss: 8166584.5000\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 11102976.0000 - val_loss: 7982208.5000\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 9427222.0000 - val_loss: 7858060.5000\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 15776217.0000 - val_loss: 7858013.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 11696693.0000 - val_loss: 7995093.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 10154951.0000 - val_loss: 8153765.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 11044636.0000 - val_loss: 8245188.5000\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 9531172.0000 - val_loss: 8174732.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 9762531.0000 - val_loss: 7991747.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 14415743.0000 - val_loss: 7857070.5000\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 10094581.0000 - val_loss: 7736728.5000\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 8633266.0000 - val_loss: 7693037.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 8987014.0000 - val_loss: 7659606.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 9599597.0000 - val_loss: 7639081.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 10421047.0000 - val_loss: 7623667.5000\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 8352066.0000 - val_loss: 7619576.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 14621565.0000 - val_loss: 7608622.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 8095466.5000 - val_loss: 7564556.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 9610215.0000 - val_loss: 7538443.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 9832331.0000 - val_loss: 7464918.5000\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 9464502.0000 - val_loss: 7423246.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 14857843.0000 - val_loss: 7383718.5000\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 9521061.0000 - val_loss: 7287340.5000\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 10653643.0000 - val_loss: 7193852.5000\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 9203522.0000 - val_loss: 7100006.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 7327352.0000 - val_loss: 7040061.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 7435464.0000 - val_loss: 7030411.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 8223160.5000 - val_loss: 7058230.5000\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 9307533.0000 - val_loss: 6990477.5000\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 8549560.0000 - val_loss: 6904158.5000\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 14046076.0000 - val_loss: 6797868.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 10008966.0000 - val_loss: 6684107.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 8740157.0000 - val_loss: 6617144.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 8894262.0000 - val_loss: 6518455.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 9063476.0000 - val_loss: 6451017.5000\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 9587128.0000 - val_loss: 6414634.5000\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 13027371.0000 - val_loss: 6345912.5000\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 8104295.0000 - val_loss: 6289024.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 10850358.0000 - val_loss: 6262938.5000\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 8067982.0000 - val_loss: 6266719.5000\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 7461365.5000 - val_loss: 6319958.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 7081129.5000 - val_loss: 6354392.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 6156154.5000 - val_loss: 6327131.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 9608257.0000 - val_loss: 6315392.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 7575490.0000 - val_loss: 6216662.5000\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 9178831.0000 - val_loss: 6188042.5000\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 8024175.5000 - val_loss: 6190779.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 6461966.0000 - val_loss: 6217970.5000\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 6478994.0000 - val_loss: 6356322.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 9835602.0000 - val_loss: 6450238.5000\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 9488932.0000 - val_loss: 6365274.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 6615479.5000 - val_loss: 6284510.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 11286528.0000 - val_loss: 6366575.5000\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 6193831.5000 - val_loss: 6355919.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 7181255.5000 - val_loss: 6512621.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 11264409.0000 - val_loss: 6532677.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 7048979.0000 - val_loss: 6459918.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 6971533.5000 - val_loss: 6517342.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 10864758.0000 - val_loss: 6564503.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 8189303.5000 - val_loss: 6575396.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 8513482.0000 - val_loss: 6497294.5000\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 7898586.0000 - val_loss: 6478247.5000\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 5714833.0000 - val_loss: 6473585.5000\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 11238001.0000 - val_loss: 6577796.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 7620913.5000 - val_loss: 6647811.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 8251106.0000 - val_loss: 6697027.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 7158770.5000 - val_loss: 6628689.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 8673850.0000 - val_loss: 6613306.5000\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 6705935.5000 - val_loss: 6600119.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 7420795.0000 - val_loss: 6664445.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 10159853.0000 - val_loss: 6740223.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 6718298.0000 - val_loss: 6661412.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 7214388.0000 - val_loss: 6696297.5000\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 7384138.5000 - val_loss: 6846801.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 10366739.0000 - val_loss: 7070286.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 7409810.5000 - val_loss: 6994637.5000\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 7328753.5000 - val_loss: 6913480.5000\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 6004680.5000 - val_loss: 6794902.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 5885023.0000 - val_loss: 6924474.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 5426958.0000 - val_loss: 7009642.5000\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 5947777.0000 - val_loss: 7359315.5000\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 8987784.0000 - val_loss: 7683563.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 8790523.0000 - val_loss: 7326405.5000\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 6185724.5000 - val_loss: 7068466.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 6314877.5000 - val_loss: 6988044.5000\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 5631178.0000 - val_loss: 7184474.5000\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 6599365.0000 - val_loss: 7705794.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 9635972.0000 - val_loss: 7657219.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 6728185.5000 - val_loss: 7265777.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 5311599.0000 - val_loss: 7075168.5000\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 5434611.5000 - val_loss: 7380997.5000\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 8800570.0000 - val_loss: 7797220.5000\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 5672243.5000 - val_loss: 7550815.5000\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 26504), started 0:14:20 ago. (Use '!kill 26504' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4c5dac48dc384e00\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4c5dac48dc384e00\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Create a logs directory using current timestamp\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# (Re)create and train the model with the TensorBoard callback,\n",
    "# so that training logs get saved.\n",
    "cnn_model = create_cnn_model((feature_matrix.shape[1], 1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, output, test_size=0.2, random_state=42)\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "cnn_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test_cnn, y_test),\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=1\n",
    ")\n",
    "%load_ext tensorboard\n",
    "# Launch tensorboard (adjust the --logdir path if needed)\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Example Input: [-1.30978394e+00 -1.30010307e+00  8.25705230e-01  3.31037372e-01\n",
      " -3.08806896e-01  4.08945709e-01  1.14933610e+00 -3.83327529e-02\n",
      " -6.71126723e-01  3.53949487e-01 -1.69453546e-01 -1.22124732e+00\n",
      " -3.96527797e-01 -1.14916480e+00  3.58762175e-01  3.78776878e-01\n",
      "  9.05400634e-01  1.94160819e+00  8.04660797e-01 -1.32225335e+00\n",
      " -4.19817045e-02 -1.97264537e-01 -1.58748552e-01  6.07734859e-01\n",
      " -1.77657396e-01  5.08582115e-01 -7.63357580e-01 -7.50062943e-01\n",
      " -4.75394666e-01  1.12984478e+00 -6.08671606e-01  1.91492010e-02\n",
      " -1.38749886e+00  6.22744739e-01  7.81456649e-01 -9.65853155e-01\n",
      " -6.87889218e-01 -1.05017543e+00 -2.14500025e-01  6.43548369e-01\n",
      " -1.96617448e+00  1.84712291e-01  3.60025853e-01 -6.28009260e-01\n",
      "  1.37049997e+00  1.18236184e+00  1.10573542e+00 -7.95287132e-01\n",
      "  5.20733476e-01  6.74404681e-01 -2.33746767e-01  1.00349069e+00\n",
      " -5.13061345e-01  8.07707846e-01 -1.46388412e-01  7.93241024e-01\n",
      " -1.13919771e+00  2.70261705e-01  5.18080831e-01 -1.33827913e+00\n",
      " -4.71448660e-01  8.96744192e-01 -1.04194447e-01 -6.17780209e-01\n",
      " -1.04024255e+00 -1.29167628e+00  7.58605674e-02 -7.56284893e-01\n",
      " -1.06496835e+00  1.98198795e-01  3.21385175e-01 -1.79390997e-01\n",
      "  2.81212479e-01 -1.87333310e+00  6.84026718e-01  9.45244670e-01\n",
      "  9.14417878e-02 -2.25650191e+00  9.72800981e-03  8.82492244e-01\n",
      " -6.75626397e-01 -2.79449463e-01  1.22823548e+00  3.66539240e-01\n",
      " -2.30123233e-02 -1.34087849e+00 -2.17538953e-01  1.52395952e+00\n",
      " -5.21135092e-01 -1.63089946e-01  2.38220051e-01  1.31555438e+00\n",
      " -7.02717245e-01 -1.25369728e-01 -1.24602568e+00  6.50199294e-01\n",
      " -1.78577447e+00  6.79447114e-01 -1.49464309e+00  5.57851255e-01\n",
      " -1.15760505e+00 -7.00751483e-01 -1.16871452e+00  6.00052714e-01\n",
      "  3.02515924e-01 -3.70094568e-01  3.47004920e-01 -1.79423928e+00\n",
      "  8.39334190e-01  1.02471530e+00  5.25710285e-01  3.78282964e-01\n",
      "  1.12970209e+00  1.36973453e+00 -1.33964789e+00 -1.05229449e+00\n",
      " -1.11019957e+00 -1.13096035e+00 -1.26381981e+00 -1.37956023e+00\n",
      " -1.00456320e-01 -2.11116865e-01 -8.55782509e-01  5.17171502e-01\n",
      " -5.08363307e-01  4.91421789e-01  1.44040450e-01 -1.42075670e+00\n",
      " -1.29712594e+00  5.96504033e-01 -1.07501447e+00  5.79183877e-01\n",
      "  7.74464667e-01 -1.28174340e-02 -5.33333957e-01  9.19605255e-01\n",
      "  6.30292594e-01  2.27958298e+00 -1.37299085e+00 -2.26967558e-01\n",
      " -9.97653008e-01 -2.53403211e+00 -5.63347340e-01  6.19346440e-01\n",
      " -3.30977052e-01 -2.14107156e+00 -3.35930198e-01 -1.20658410e+00\n",
      " -1.22418892e+00 -7.77485818e-02  5.87669075e-01 -1.05902994e+00\n",
      " -6.62271306e-02 -6.61412120e-01  2.66431421e-01  9.98027921e-01\n",
      "  1.66364431e-01  3.31942707e-01 -1.09508836e+00 -8.42802227e-01\n",
      "  6.07064188e-01  9.66909528e-01 -2.20128462e-01 -1.15928447e+00\n",
      " -2.01056767e-02  7.88415313e-01  6.93823934e-01 -1.11019397e+00\n",
      "  2.67774016e-01  1.28493890e-01 -1.93852291e-01  6.27763420e-02\n",
      " -4.25042063e-01 -8.55217338e-01 -5.55954814e-01 -1.10095620e+00\n",
      " -5.04040301e-01  2.00905561e-01 -6.86134249e-02 -4.80805933e-01\n",
      "  1.26690522e-03 -9.25524607e-02 -9.70768780e-02  3.95029992e-01\n",
      " -6.45252049e-01 -1.65615153e+00  7.04321206e-01 -6.35385737e-02\n",
      "  2.03115225e-01  2.83071905e-01  3.72607440e-01 -1.26708519e+00\n",
      "  1.40478587e+00  1.05313957e+00  9.02172327e-02 -1.23613822e+00\n",
      "  6.28748357e-01  6.18487418e-01 -1.63881287e-01 -7.45593190e-01\n",
      " -2.54252583e-01  8.63047242e-01  3.30937207e-01  3.77934039e-01\n",
      "  5.18658936e-01 -8.35669160e-01  3.89955342e-02  1.74557137e+00\n",
      " -4.39579725e-01 -1.63589939e-01  5.58458745e-01  5.58634758e-01\n",
      " -1.10521042e+00  1.19370759e+00 -1.87799782e-01 -4.34024543e-01\n",
      " -5.02302706e-01  4.54692394e-01  2.31835961e-01 -1.47833601e-01\n",
      " -1.09194815e+00  9.54343259e-01 -1.80315718e-01  7.79147565e-01\n",
      "  1.28809845e+00 -1.25861419e-02  5.53975403e-01  6.36903465e-01\n",
      "  1.20730817e+00  1.00187838e+00 -7.36683190e-01  2.12702438e-01\n",
      " -4.81054842e-01  1.04265761e+00  1.17222393e+00 -6.97532892e-02\n",
      " -1.29853463e+00  7.96602547e-01  1.44602644e+00 -7.26748049e-01\n",
      " -5.14183342e-01  8.20510805e-01  1.36501288e+00  1.07876480e+00\n",
      " -2.00098395e+00  3.49928230e-01 -5.59914410e-01 -4.33257580e-01\n",
      "  5.06940007e-01 -2.81677514e-01  1.13201961e-01 -3.51178914e-01\n",
      "  3.16499799e-01  2.30038762e-01 -5.30529797e-01 -3.72183800e-01\n",
      "  2.60479748e-01 -4.31779549e-02  1.21860290e+00 -5.78329980e-01\n",
      " -1.17551816e+00  5.73628306e-01 -1.84848398e-01 -9.46589649e-01\n",
      " -3.21812518e-02 -3.69162291e-01 -4.11942005e-01  1.44413567e+00\n",
      "  1.82429993e+00 -1.30375159e+00 -6.28812015e-01  5.83208561e-01\n",
      " -7.92191029e-01 -8.71175408e-01  6.41714096e-01 -7.87058249e-02\n",
      " -4.78948265e-01  8.62811387e-01 -6.44294798e-01  1.12592864e+00\n",
      "  1.43359542e+00 -2.32890144e-01  1.81453669e+00  1.33592486e+00\n",
      "  6.94150385e-03  7.83264041e-01  9.36051458e-02  1.90481603e+00\n",
      " -3.99359286e-01 -3.76753151e-01 -1.93509865e+00  1.14153707e-02\n",
      "  7.86322594e-01  1.54072928e+00 -2.17395097e-01  1.49841225e+00\n",
      " -4.60749149e-01 -3.41077000e-01  1.43405950e+00 -7.40221798e-01\n",
      "  4.80756074e-01 -1.11086869e+00 -9.94794726e-01 -7.11821377e-01\n",
      "  6.52263761e-01  3.42148572e-01 -1.11525309e+00 -6.39188811e-02\n",
      "  5.24796486e-01  5.06580293e-01 -3.58251095e-01 -9.00234282e-01\n",
      "  1.77014530e+00 -1.36183411e-01 -3.89340401e-01  8.89234006e-01\n",
      " -5.89567840e-01  4.72719878e-01 -1.40482652e+00  2.38595933e-01\n",
      "  9.01597857e-01 -7.74367332e-01  2.15482578e-01 -1.03820336e+00\n",
      "  7.64468133e-01 -4.82295342e-02  3.31417145e-03 -2.58255869e-01\n",
      "  4.75772411e-01 -1.43544030e+00  2.98272222e-01 -1.19894981e+00\n",
      " -4.58918184e-01  1.45274866e+00 -4.69384044e-01  2.74261475e-01\n",
      " -1.69975460e-02  4.47503150e-01  8.75111163e-01 -9.74930167e-01\n",
      " -5.03029525e-01  1.32345963e+00 -8.06075856e-02  3.74333203e-01\n",
      "  6.15350641e-02 -2.40844473e-01 -5.72671115e-01 -4.02280003e-01\n",
      " -9.29009318e-01  1.75017402e-01  6.93866730e-01  3.19856644e-01\n",
      " -1.11511365e-01  5.33608735e-01 -6.51259601e-01  1.43490219e+00\n",
      "  7.79901505e-01 -1.48051098e-01  1.99866548e-01 -9.92670730e-02\n",
      "  8.65363479e-01  2.34211341e-01  1.90114498e-01  8.90300632e-01\n",
      "  2.09874250e-02 -9.89571631e-01 -7.80868471e-01  4.30543087e-02\n",
      "  7.11884677e-01 -3.19925117e+00  1.30400285e-01 -1.92484367e+00\n",
      " -3.88657600e-01  6.19629212e-02 -8.69729996e-01 -3.49689692e-01\n",
      "  2.16069743e-01  5.06062806e-01 -1.00716248e-01 -1.32627577e-01\n",
      "  1.77442062e+00  4.45706099e-01  3.25637460e-02 -1.47142386e+00\n",
      " -3.99113864e-01 -6.92682743e-01 -2.00414229e-02  6.94142520e-01\n",
      "  7.35059977e-02 -1.73467427e-01  7.26342857e-01  5.20546138e-01\n",
      " -9.66682136e-01  4.78396356e-01  4.99607980e-01 -5.28941870e-01\n",
      "  1.31692812e-01 -3.71336222e-01 -6.54021442e-01  9.74952519e-01\n",
      "  2.44566575e-01 -7.12687612e-01  1.01572835e+00 -6.71925068e-01\n",
      "  1.02846026e+00  5.77665210e-01  5.41216910e-01 -9.38347995e-01\n",
      "  3.78806800e-01 -1.03401780e-01  1.52777016e+00 -4.89968717e-01\n",
      " -1.57155152e-02 -5.94153106e-01  4.36087877e-01 -4.24607694e-01\n",
      " -3.80487382e-01 -7.34389126e-01 -2.66691327e-01 -6.82514489e-01\n",
      " -1.01936221e-01  8.24747920e-01  3.66825730e-01  7.39605010e-01\n",
      "  2.70603716e-01 -4.83794697e-02  1.35430172e-01 -1.42821655e-01\n",
      "  4.00786072e-01  1.31528127e+00  1.83035290e+00  2.07087994e-01\n",
      "  3.42016250e-01  4.67967361e-01  4.41871822e-01 -7.22906172e-01\n",
      "  7.03337491e-01  6.03959501e-01 -1.50814044e+00  1.50781125e-01\n",
      "  1.90930140e+00 -8.27923715e-01  5.85034251e-01 -6.58783317e-01\n",
      " -6.67440236e-01 -8.99701476e-01  2.72241328e-02  2.40594149e-04\n",
      "  7.65717089e-01 -2.01938823e-01  1.00212443e+00 -2.54954267e+00\n",
      " -2.31397319e+00 -1.25261617e+00  1.02170181e+00  1.12089670e+00\n",
      " -7.69376755e-01  1.32096219e+00 -9.80557740e-01  2.59172410e-01\n",
      " -7.18094409e-01  6.09947622e-01  1.21546514e-01  4.48377505e-02\n",
      " -1.08042991e+00  8.73244703e-01 -7.17432559e-01  1.21550985e-01\n",
      "  5.46935737e-01  7.58304894e-01 -1.05929267e+00 -1.21208024e+00\n",
      " -7.58481145e-01  6.73695505e-01  1.69293165e-01 -7.86944270e-01\n",
      "  6.38615787e-01 -8.77046138e-02  2.41288260e-01 -7.40375161e-01\n",
      "  7.41216689e-02  1.50236130e-01  4.79225785e-01 -1.56594187e-01\n",
      " -7.73811340e-01  7.87353694e-01  2.79000580e-01  3.04774016e-01\n",
      "  8.89678955e-01  8.44518915e-02  3.99645478e-01  7.09541380e-01\n",
      "  3.24597299e-01  2.63692439e-01  4.65103298e-01  7.03619540e-01\n",
      " -6.50276244e-01 -7.61234820e-01 -3.91400665e-01 -1.39395997e-01\n",
      "  1.69238341e+00  9.13439155e-01  6.09670281e-01 -5.76900959e-01\n",
      " -1.88720047e+00  1.55173644e-01  3.59800339e-01 -3.29747528e-01\n",
      "  6.16226733e-01  4.89332020e-01  3.43690634e-01 -7.62248874e-01\n",
      " -1.01630700e+00 -8.17750931e-01 -7.05588222e-01  5.01402952e-02\n",
      " -1.05295546e-01 -6.48349345e-01 -3.75824004e-01  1.20784450e+00\n",
      "  1.31391227e+00 -9.36338067e-01  1.02286565e+00 -8.76341999e-01\n",
      " -1.52516389e+00 -4.30717975e-01 -1.60042822e+00  5.31320393e-01\n",
      " -2.03003001e+00 -6.49712145e-01 -6.21535957e-01  6.95871472e-01\n",
      " -8.37550536e-02  8.31281364e-01 -2.63224870e-01  6.38908565e-01\n",
      "  2.72148937e-01  1.52044201e+00  9.05685842e-01 -1.91111013e-01\n",
      " -1.84996128e-01  4.41491306e-01 -5.35717607e-01  1.84186414e-01\n",
      " -2.29575232e-01 -1.69201028e+00 -6.49396479e-01 -5.83737083e-02\n",
      "  9.74235952e-01 -1.22420144e+00  5.72108105e-02  3.69889468e-01\n",
      " -8.02339077e-01  1.32052875e+00 -1.03790593e+00 -5.84348245e-03\n",
      " -2.52497971e-01  9.34546053e-01 -9.22064930e-02  2.09503368e-01\n",
      "  6.88757539e-01  4.90594131e-04  9.33553874e-01  1.10644472e+00\n",
      "  6.68088555e-01 -6.20681047e-02  6.11317515e-01  4.10029441e-01\n",
      " -8.50424111e-01  3.96084756e-01 -7.24365771e-01 -1.00423419e+00\n",
      "  2.46873662e-01 -1.08627208e-01 -1.09993672e+00  1.38673365e+00\n",
      "  1.61946189e+00  6.22902438e-02 -2.80777484e-01  1.00519407e+00\n",
      "  3.59434754e-01 -8.61117169e-02 -7.36551702e-01  1.22437227e+00\n",
      "  4.89320606e-01 -6.35378435e-02  2.27245182e-01  1.28481179e-01\n",
      "  9.28206861e-01 -3.86299081e-02  8.25591266e-01 -4.68770653e-01\n",
      "  1.06914032e+00  1.34329879e+00  7.90177763e-01  1.30411029e+00\n",
      "  5.44920862e-01  9.08925354e-01 -8.23442638e-01  1.07439101e+00\n",
      " -2.61987239e-01  1.21847939e+00  4.17478532e-01  1.33776581e+00\n",
      "  8.79239857e-01 -6.91045165e-01 -1.10399926e+00  6.91630319e-02\n",
      "  8.38372827e-01  5.64538121e-01  2.12288946e-01 -8.09177041e-01\n",
      " -5.92870712e-01  9.18727398e-01 -3.80412757e-01 -2.07850575e-01\n",
      "  2.20866292e-03 -5.96290492e-02 -5.94696999e-02  1.51794827e+00\n",
      "  5.70376851e-02  1.22251201e+00 -5.43037569e-03  3.39280516e-01\n",
      " -1.03384995e+00  1.72356978e-01 -9.09321725e-01  1.23319125e+00\n",
      "  7.38304317e-01  1.15565848e+00  7.00066268e-01 -3.25466365e-01\n",
      "  4.04859036e-01  1.37781131e+00  1.74017772e-01  4.39487159e-01\n",
      " -9.41211045e-01  7.64703974e-02  6.15492821e-01  2.59363800e-01\n",
      " -2.12391391e-01 -1.23333013e+00 -1.97030354e+00  2.03175521e+00\n",
      "  6.57665431e-02 -1.72700286e-01  5.59002995e-01 -2.16091558e-01\n",
      " -1.04733694e+00 -4.46244031e-01  8.91148299e-02  1.19924617e+00\n",
      " -9.00695920e-01  5.25695443e-01  8.81426156e-01  1.52428066e-02\n",
      "  4.53951210e-01  1.37084633e-01  1.30762827e+00  5.82493603e-01\n",
      "  8.48297656e-01  3.49907547e-01 -1.69461593e-01 -1.22184940e-01\n",
      " -1.01469137e-01 -6.93418324e-01 -4.77860034e-01  2.21788549e+00\n",
      "  1.10553229e+00  1.50142936e-02 -1.94660389e+00  7.51836896e-01\n",
      "  1.81932926e+00 -2.12192640e-01 -6.47278726e-01 -1.83955789e-01\n",
      "  1.37472665e-02 -4.72014666e-01 -6.83490634e-01 -6.45214736e-01\n",
      "  3.57633382e-01 -9.86117482e-01 -1.42302978e+00  5.57807028e-01\n",
      " -2.98220187e-01 -6.75843656e-02  1.04351306e+00 -1.12408471e+00\n",
      "  2.57832676e-01 -1.41240227e+00  4.85766917e-01  1.12754963e-01\n",
      "  1.54266074e-01 -1.04321398e-01 -8.04941475e-01  3.29863012e-01\n",
      "  2.73989379e-01 -1.68090320e+00 -1.04407883e+00 -1.75858617e-01\n",
      "  2.91035146e-01  2.61145711e-01 -7.90660262e-01 -5.75069413e-02\n",
      " -1.27892184e+00 -1.11153319e-01  5.84961697e-02  2.23284587e-01\n",
      " -4.31369394e-01  7.71447539e-01  1.32605612e-01 -2.28056955e+00\n",
      " -4.79810417e-01  2.50111490e-01  1.05719805e-01  4.25569683e-01\n",
      " -1.18771926e-01 -1.31088331e-01 -6.96813285e-01  3.79977375e-01\n",
      "  4.83761370e-01 -8.06749821e-01  4.71721232e-01 -5.47628582e-01\n",
      "  1.18086323e-01 -2.31677532e-01  8.29930186e-01 -5.69367051e-01\n",
      " -1.79082847e+00 -3.91749859e-01  2.93771923e-01  1.02003312e+00\n",
      "  1.36190325e-01  1.21903014e+00  4.05862629e-01 -1.76399171e+00\n",
      " -1.16298962e+00  1.01952398e+00  2.06691369e-01  1.77833939e+00\n",
      " -1.23983636e-01 -1.57401311e+00  6.69873238e-01 -1.17370903e+00\n",
      "  7.15185225e-01  5.76975644e-01  3.54861528e-01 -9.71304417e-01\n",
      " -3.94806534e-01  1.06103134e+00 -3.99184316e-01 -1.56668651e+00\n",
      " -8.02627981e-01  1.14835036e+00  1.50185025e+00  3.65326464e-01\n",
      "  1.69350728e-01 -1.47324633e-02 -5.22411883e-01 -1.26750171e+00\n",
      " -3.35943289e-02  1.12659299e+00  3.17100465e-01  1.33127436e-01\n",
      " -2.18943074e-01  7.89045811e-01 -2.87027359e-01 -3.66496891e-01]\n",
      "SMILES: N#CC#N\n",
      "Prediction: -1029.6884765625\n",
      "Target: -1097.07\n"
     ]
    }
   ],
   "source": [
    "# Select an example index\n",
    "example_index = 400\n",
    "\n",
    "# Get the example input, prediction, and target\n",
    "example_input = feature_matrix[example_index]\n",
    "example_prediction = model.predict(example_input.reshape(1, -1, 1))\n",
    "example_target = output.iloc[example_index]\n",
    "smile = input.iloc[example_index]\n",
    "print(f\"Example Input: {example_input}\")\n",
    "print(f\"SMILES: {smile}\")\n",
    "print(f\"Prediction: {example_prediction[0][0]}\")\n",
    "print(f\"Target: {example_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Target</th>\n",
       "      <th>Discrepancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>C(CCC(=O)O)CC(=O)O</td>\n",
       "      <td>1067.860962</td>\n",
       "      <td>4863.73</td>\n",
       "      <td>3795.869038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>C(CCC(=O)O)CC(=O)O</td>\n",
       "      <td>1067.860962</td>\n",
       "      <td>4863.73</td>\n",
       "      <td>3795.869038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>C(CCC(=O)O)CC(=O)O</td>\n",
       "      <td>1067.860962</td>\n",
       "      <td>4863.73</td>\n",
       "      <td>3795.869038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>CC1C2CCC1CC(C2)OC(=O)C3=CC(=CC(=C3)Cl)Cl</td>\n",
       "      <td>-38064.386719</td>\n",
       "      <td>-35099.60</td>\n",
       "      <td>2964.786719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>CC1C2CCC1CC(C2)OC(=O)C3=CC(=CC(=C3)Cl)Cl</td>\n",
       "      <td>-38064.386719</td>\n",
       "      <td>-35099.60</td>\n",
       "      <td>2964.786719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>CC1C2CCC1CC(C2)OC(=O)C3=CC(=CC(=C3)Cl)Cl</td>\n",
       "      <td>-38064.386719</td>\n",
       "      <td>-35099.60</td>\n",
       "      <td>2964.786719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>C1=NC(=C(N1)C(=O)O)N</td>\n",
       "      <td>1041.532104</td>\n",
       "      <td>-1910.62</td>\n",
       "      <td>2952.152104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>C1=NC(=C(N1)C(=O)O)N</td>\n",
       "      <td>1041.532104</td>\n",
       "      <td>-1910.62</td>\n",
       "      <td>2952.152104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>C1=NC(=C(N1)C(=O)O)N</td>\n",
       "      <td>1041.532104</td>\n",
       "      <td>-1910.62</td>\n",
       "      <td>2952.152104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>C1=CC=C2C(=C1)C3=CC=CC=C3N2</td>\n",
       "      <td>7133.939453</td>\n",
       "      <td>10040.60</td>\n",
       "      <td>2906.660547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SMILES    Prediction    Target  \\\n",
       "471                        C(CCC(=O)O)CC(=O)O   1067.860962   4863.73   \n",
       "756                        C(CCC(=O)O)CC(=O)O   1067.860962   4863.73   \n",
       "186                        C(CCC(=O)O)CC(=O)O   1067.860962   4863.73   \n",
       "554  CC1C2CCC1CC(C2)OC(=O)C3=CC(=CC(=C3)Cl)Cl -38064.386719 -35099.60   \n",
       "839  CC1C2CCC1CC(C2)OC(=O)C3=CC(=CC(=C3)Cl)Cl -38064.386719 -35099.60   \n",
       "269  CC1C2CCC1CC(C2)OC(=O)C3=CC(=CC(=C3)Cl)Cl -38064.386719 -35099.60   \n",
       "167                      C1=NC(=C(N1)C(=O)O)N   1041.532104  -1910.62   \n",
       "737                      C1=NC(=C(N1)C(=O)O)N   1041.532104  -1910.62   \n",
       "452                      C1=NC(=C(N1)C(=O)O)N   1041.532104  -1910.62   \n",
       "563               C1=CC=C2C(=C1)C3=CC=CC=C3N2   7133.939453  10040.60   \n",
       "\n",
       "     Discrepancy  \n",
       "471  3795.869038  \n",
       "756  3795.869038  \n",
       "186  3795.869038  \n",
       "554  2964.786719  \n",
       "839  2964.786719  \n",
       "269  2964.786719  \n",
       "167  2952.152104  \n",
       "737  2952.152104  \n",
       "452  2952.152104  \n",
       "563  2906.660547  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Target</th>\n",
       "      <th>Discrepancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>C1=CC(=C[N+](=C1)C2C(C(C(O2)COP(=O)(O)O)O)O)C(...</td>\n",
       "      <td>-709.552795</td>\n",
       "      <td>-715.90</td>\n",
       "      <td>6.347205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>C(CN)C=O</td>\n",
       "      <td>4164.063477</td>\n",
       "      <td>4159.50</td>\n",
       "      <td>4.563477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>C(CN)C=O</td>\n",
       "      <td>4164.063477</td>\n",
       "      <td>4159.50</td>\n",
       "      <td>4.563477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>C(CN)C=O</td>\n",
       "      <td>4164.063477</td>\n",
       "      <td>4159.50</td>\n",
       "      <td>4.563477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>N#CC#N</td>\n",
       "      <td>-1093.251465</td>\n",
       "      <td>-1097.07</td>\n",
       "      <td>3.818535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>N#CC#N</td>\n",
       "      <td>-1093.251465</td>\n",
       "      <td>-1097.07</td>\n",
       "      <td>3.818535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>N#CC#N</td>\n",
       "      <td>-1093.251465</td>\n",
       "      <td>-1097.07</td>\n",
       "      <td>3.818535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>NC</td>\n",
       "      <td>-1088.399658</td>\n",
       "      <td>-1086.81</td>\n",
       "      <td>1.589658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>NC</td>\n",
       "      <td>-1088.399658</td>\n",
       "      <td>-1086.81</td>\n",
       "      <td>1.589658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>NC</td>\n",
       "      <td>-1088.399658</td>\n",
       "      <td>-1086.81</td>\n",
       "      <td>1.589658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SMILES   Prediction   Target  \\\n",
       "499  C1=CC(=C[N+](=C1)C2C(C(C(O2)COP(=O)(O)O)O)O)C(...  -709.552795  -715.90   \n",
       "433                                           C(CN)C=O  4164.063477  4159.50   \n",
       "148                                           C(CN)C=O  4164.063477  4159.50   \n",
       "718                                           C(CN)C=O  4164.063477  4159.50   \n",
       "400                                             N#CC#N -1093.251465 -1097.07   \n",
       "115                                             N#CC#N -1093.251465 -1097.07   \n",
       "685                                             N#CC#N -1093.251465 -1097.07   \n",
       "388                                                 NC -1088.399658 -1086.81   \n",
       "103                                                 NC -1088.399658 -1086.81   \n",
       "673                                                 NC -1088.399658 -1086.81   \n",
       "\n",
       "     Discrepancy  \n",
       "499     6.347205  \n",
       "433     4.563477  \n",
       "148     4.563477  \n",
       "718     4.563477  \n",
       "400     3.818535  \n",
       "115     3.818535  \n",
       "685     3.818535  \n",
       "388     1.589658  \n",
       "103     1.589658  \n",
       "673     1.589658  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# First, reshape the feature matrix as required by the CNN model\n",
    "X_all = feature_matrix.reshape((feature_matrix.shape[0], feature_matrix.shape[1], 1))\n",
    "\n",
    "# Generate predictions for all samples using the previously trained model\n",
    "preds = model.predict(X_all).flatten()\n",
    "\n",
    "# Calculate the absolute discrepancy between predictions and targets\n",
    "discrepancy = np.abs(preds - output.to_numpy())\n",
    "\n",
    "# Create a new DataFrame with SMILES, Prediction, Target, and Discrepancy columns\n",
    "results_df = pd.DataFrame({\n",
    "    'SMILES': input,\n",
    "    'Prediction': preds,\n",
    "    'Target': output,\n",
    "    'Discrepancy': discrepancy\n",
    "})\n",
    "\n",
    "results_df = results_df.sort_values(by='Discrepancy', ascending=False)\n",
    "# Display the resulting table\n",
    "display(results_df.head(10))\n",
    "display(results_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```flowchart TD\n",
    "    A[Input Layer<br/>(input_shape)]\n",
    "    B[Conv1D<br/>32 filters, kernel size=3<br/>(ReLU)]\n",
    "    C[Flatten]\n",
    "    D[Dense Layer<br/>128 units, ReLU]\n",
    "    E[Dropout<br/>(rate = 0.3)]\n",
    "    F[Dense Layer<br/>128 units, ReLU]\n",
    "    G[Dense Layer<br/>1 unit, Linear]\n",
    "    \n",
    "    A --> B\n",
    "    B --> C\n",
    "    C --> D\n",
    "    D --> E\n",
    "    E --> F\n",
    "    F --> G```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bias ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
